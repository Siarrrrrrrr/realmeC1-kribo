--- mm/vmscan.c
+++ mm/vmscan.c
@@ -2183,6 +2244,8 @@ static void get_scan_count(struct lruvec *lruvec, struct mem_cgroup *memcg,
 	if (!global_reclaim(sc))
 		force_scan = true;
 
+	prepare_workingset_protection(pgdat, sc);
+
 	/* If we have no swap space, do not bother scanning anon pages. */
 	if (!sc->may_swap || mem_cgroup_get_nr_swap_pages(memcg) <= 0) {
 		scan_balance = SCAN_FILE;
@@ -2361,6 +2433,25 @@ static void get_scan_count(struct lruvec *lruvec, struct mem_cgroup *memcg,
 				BUG();
 			}
 
+			/*
+			 * Hard protection of the working set.
+			 */
+			if (file) {
+				/*
+				 * Don't reclaim file pages when the amount of
+				 * clean file pages is below vm.clean_min_kbytes.
+				 */
+				if (sc->clean_below_min)
+					scan = 0;
+			} else {
+				/*
+				 * Don't reclaim anonymous pages when their
+				 * amount is below vm.anon_min_kbytes.
+				 */
+				if (sc->anon_below_min)
+					scan = 0;
+			}
+
 			*lru_pages += size;
 			nr[lru] = scan;
 
